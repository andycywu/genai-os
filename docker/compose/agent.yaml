services:
  agent-executor:
    image: kuwaai/model-executor
    environment:
      CUSTOM_EXECUTOR_PATH: ./agent/main.py
      EXECUTOR_ACCESS_CODE: agent
      EXECUTOR_NAME: Agent
      EXECUTOR_IMAGE: iteration.png # Refer to src/multi-chat/public/images
      TRANSFORMERS_OFFLINE: ${TRANSFORMERS_OFFLINE:-0} # For embedding model
    depends_on:
      - executor-builder
      - kernel
      - multi-chat
    command: [
      # "--api_base_url", "http://${DOMAIN_NAME}/",
      "--log", "debug",
    ]
    volumes: [
      "kuwa-root:/var/kuwa/docker/root:rw", # The root of Kuwa filesystem hierarchy to store user-uploaded data during runtime.
      "~/.cache/huggingface:/root/.cache/huggingface"
    ]
    extra_hosts:
      - "localhost:host-gateway"
    restart: unless-stopped
    networks: ["backend", "frontend"]